## 前言

> 芯片的算力不一定和模型推理速度成正比，嵌入式 `AI` 的另一个核心是 `inference` 框架。对于 `CPU` 架构来说，是否使用 `SIMD`（ `ARM从v7` 开始就支持 `NEON` 指令了）、是否使用多核多线程、是否有高效的卷积实现方式、是否有做汇编优化等等都会极大影响模型运行速度；而对 `DSP/NPU` 等硬件架构来说，是否对模型进行量化推理、量化的方式、访存的优化等也会有很大影响。
